{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating diffusion bridge for periodic sine drift with some current methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DiffusionBridge as db\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem settings\n",
    "d = 1\n",
    "theta = torch.tensor(math.pi)\n",
    "# alpha = torch.tensor(1.0)\n",
    "alpha = torch.tensor(4.0)\n",
    "f = lambda t,x: alpha * torch.sin(x - theta)  \n",
    "sigma = torch.tensor(1.0)\n",
    "T = torch.tensor(1.0)\n",
    "M = 50\n",
    "diffusion = db.diffusion.model(f, sigma, d, T, M)\n",
    "\n",
    "# # initial and terminal constraints\n",
    "X0 = 0.1 * torch.ones(d)\n",
    "XT = 1.0 * torch.ones(d)\n",
    "\n",
    "# repetitions\n",
    "N = 2**10\n",
    "R = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn backward diffusion bridge process with score matching\n",
    "epsilon = 1e-3\n",
    "minibatch = 100\n",
    "num_iterations = 500\n",
    "learning_rate = 0.01\n",
    "ema_momentum = 0.99\n",
    "output = diffusion.learn_score_transition(X0, XT, epsilon, minibatch, num_iterations, learning_rate, ema_momentum)\n",
    "score_transition_net = output['net']\n",
    "\n",
    "# simulate backward diffusion bridge (BDB) process with approximate score\n",
    "BDB = {'ess' : torch.zeros(R), 'logestimate' : torch.zeros(R), 'acceptrate' : torch.zeros(R)}\n",
    "for r in range(R):\n",
    "    with torch.no_grad():\n",
    "        output = diffusion.simulate_bridge_backwards(score_transition_net, X0, XT, epsilon, N, modify = False)\n",
    "        trajectories = output['trajectories']\n",
    "        log_proposal = output['logdensity']\n",
    "    log_target = diffusion.law_bridge(trajectories) \n",
    "    log_weights = log_target - log_proposal\n",
    "    \n",
    "    # importance sampling\n",
    "    max_log_weights = torch.max(log_weights)\n",
    "    weights = torch.exp(log_weights - max_log_weights)\n",
    "    norm_weights = weights / torch.sum(weights)\n",
    "    ess = 1.0 / torch.sum(norm_weights**2)\n",
    "    log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "    BDB['ess'][r] = ess\n",
    "    BDB['logestimate'][r] = log_transition_estimate\n",
    "    \n",
    "    # independent Metropolis-Hastings\n",
    "    initial = diffusion.simulate_bridge_backwards(score_transition_net, X0, XT, epsilon, 1, modify = False)\n",
    "    current_trajectory = initial['trajectories']\n",
    "    current_log_proposal = initial['logdensity'] \n",
    "    current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "    current_log_weight = current_log_target - current_log_proposal\n",
    "    num_accept = 0\n",
    "    for n in range(N):\n",
    "        proposed_trajectory = trajectories[n, :, :]\n",
    "        proposed_log_weight = log_weights[n]\n",
    "        log_accept_prob = proposed_log_weight - current_log_weight\n",
    "\n",
    "        if (torch.log(torch.rand(1)) < log_accept_prob):\n",
    "            current_trajectory = proposed_trajectory.clone()\n",
    "            current_log_weight = proposed_log_weight.clone()  \n",
    "            num_accept += 1\n",
    "    accept_rate = num_accept / N\n",
    "    BDB['acceptrate'][r] = accept_rate\n",
    "\n",
    "    # print\n",
    "    print('Repeat: ' + str(r) + \n",
    "          ' ESS%: ' + str(float(ess * 100 / N)) + \n",
    "          ' log-transition density: ' + str(float(log_transition_estimate)), \n",
    "          ' Accept rate: ' + str(float(accept_rate)))\n",
    "\n",
    "# simulate modified backward diffusion bridge (MBDB) process with approximate score\n",
    "MBDB = {'ess' : torch.zeros(R), 'logestimate' : torch.zeros(R), 'acceptrate' : torch.zeros(R)}\n",
    "for r in range(R):\n",
    "    with torch.no_grad():\n",
    "        output = diffusion.simulate_bridge_backwards(score_transition_net, X0, XT, epsilon, N, modify = True)\n",
    "        trajectories = output['trajectories']\n",
    "        log_proposal = output['logdensity']\n",
    "    log_target = diffusion.law_bridge(trajectories) \n",
    "    log_weights = log_target - log_proposal\n",
    "\n",
    "    # importance sampling\n",
    "    max_log_weights = torch.max(log_weights)\n",
    "    weights = torch.exp(log_weights - max_log_weights)\n",
    "    norm_weights = weights / torch.sum(weights)\n",
    "    ess = 1.0 / torch.sum(norm_weights**2)\n",
    "    log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "    MBDB['ess'][r] = ess\n",
    "    MBDB['logestimate'][r] = log_transition_estimate\n",
    "\n",
    "    # independent Metropolis-Hastings\n",
    "    initial = diffusion.simulate_bridge_backwards(score_transition_net, X0, XT, epsilon, 1, modify = True)\n",
    "    current_trajectory = initial['trajectories']\n",
    "    current_log_proposal = initial['logdensity'] \n",
    "    current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "    current_log_weight = current_log_target - current_log_proposal\n",
    "    num_accept = 0\n",
    "    for n in range(N):\n",
    "        proposed_trajectory = trajectories[n, :, :]\n",
    "        proposed_log_weight = log_weights[n]\n",
    "        log_accept_prob = proposed_log_weight - current_log_weight\n",
    "\n",
    "        if (torch.log(torch.rand(1)) < log_accept_prob):\n",
    "            current_trajectory = proposed_trajectory.clone()\n",
    "            current_log_weight = proposed_log_weight.clone()  \n",
    "            num_accept += 1\n",
    "    accept_rate = num_accept / N\n",
    "    MBDB['acceptrate'][r] = accept_rate\n",
    "\n",
    "    # print\n",
    "    print('Repeat: ' + str(r) + \n",
    "          ' ESS%: ' + str(float(ess * 100 / N)) + \n",
    "          ' log-transition density: ' + str(float(log_transition_estimate)),\n",
    "          ' Accept rate: ' + str(float(accept_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use MBDB importance sampler with large number of sample paths as ground truth\n",
    "N_large = 2**18\n",
    "with torch.no_grad():\n",
    "    output = diffusion.simulate_bridge_backwards(score_transition_net, X0, XT, epsilon, N_large, modify = True)\n",
    "    trajectories = output['trajectories']\n",
    "    log_proposal = output['logdensity']\n",
    "log_target = diffusion.law_bridge(trajectories) \n",
    "log_weights = log_target - log_proposal\n",
    "    \n",
    "# importance sampling\n",
    "max_log_weights = torch.max(log_weights)\n",
    "weights = torch.exp(log_weights - max_log_weights)\n",
    "log_transition_density = torch.log(torch.mean(weights)) + max_log_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn forward diffusion bridge process with score matching\n",
    "epsilon = 1e-3\n",
    "minibatch = 100\n",
    "num_iterations = 500\n",
    "learning_rate = 0.01\n",
    "ema_momentum = 0.99\n",
    "output = diffusion.learn_score_marginal(score_transition_net, X0, XT, epsilon, minibatch, num_iterations, learning_rate, ema_momentum)\n",
    "score_marginal_net = output['net']\n",
    "\n",
    "# simulate forward diffusion bridge (FDB) process using approximate score\n",
    "FDB = {'ess' : torch.zeros(R), 'logestimate' : torch.zeros(R), 'acceptrate' : torch.zeros(R)}\n",
    "for r in range(R):\n",
    "    with torch.no_grad():\n",
    "        output = diffusion.simulate_bridge_forwards(score_transition_net, score_marginal_net, X0, XT, epsilon, N, modify = False)\n",
    "        trajectories = output['trajectories']\n",
    "        log_proposal = output['logdensity']\n",
    "    log_target = diffusion.law_bridge(trajectories) \n",
    "    log_weights = log_target - log_proposal\n",
    "\n",
    "    # importance sampling\n",
    "    max_log_weights = torch.max(log_weights)\n",
    "    weights = torch.exp(log_weights - max_log_weights)\n",
    "    norm_weights = weights / torch.sum(weights)\n",
    "    ess = 1.0 / torch.sum(norm_weights**2)\n",
    "    log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "    FDB['ess'][r] = ess\n",
    "    FDB['logestimate'][r] = log_transition_estimate\n",
    "\n",
    "    # independent Metropolis-Hastings\n",
    "    initial = diffusion.simulate_bridge_forwards(score_transition_net, score_marginal_net, X0, XT, epsilon, 1, modify = False)\n",
    "    current_trajectory = initial['trajectories']\n",
    "    current_log_proposal = initial['logdensity'] \n",
    "    current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "    current_log_weight = current_log_target - current_log_proposal\n",
    "    num_accept = 0\n",
    "    for n in range(N):\n",
    "        proposed_trajectory = trajectories[n, :, :]\n",
    "        proposed_log_weight = log_weights[n]\n",
    "        log_accept_prob = proposed_log_weight - current_log_weight\n",
    "\n",
    "        if (torch.log(torch.rand(1)) < log_accept_prob):\n",
    "            current_trajectory = proposed_trajectory.clone()\n",
    "            current_log_weight = proposed_log_weight.clone()  \n",
    "            num_accept += 1\n",
    "    accept_rate = num_accept / N\n",
    "    FDB['acceptrate'][r] = accept_rate\n",
    "\n",
    "    # print\n",
    "    print('Repeat: ' + str(r) + \n",
    "          ' ESS%: ' + str(float(ess * 100 / N)) + \n",
    "          ' log-transition density: ' + str(float(log_transition_estimate)),\n",
    "          ' Accept rate: ' + str(float(accept_rate)))\n",
    "          \n",
    "# simulate modified forward diffusion bridge (MFDB) process using approximate score\n",
    "MFDB = {'ess' : torch.zeros(R), 'logestimate' : torch.zeros(R), 'acceptrate' : torch.zeros(R)}\n",
    "for r in range(R):\n",
    "    with torch.no_grad():\n",
    "        output = diffusion.simulate_bridge_forwards(score_transition_net, score_marginal_net, X0, XT, epsilon, N, modify = True)\n",
    "        trajectories = output['trajectories']\n",
    "        log_proposal = output['logdensity']\n",
    "    log_target = diffusion.law_bridge(trajectories) \n",
    "    log_weights = log_target - log_proposal\n",
    "\n",
    "    # importance sampling\n",
    "    max_log_weights = torch.max(log_weights)\n",
    "    weights = torch.exp(log_weights - max_log_weights)\n",
    "    norm_weights = weights / torch.sum(weights)\n",
    "    ess = 1.0 / torch.sum(norm_weights**2)\n",
    "    log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "    MFDB['ess'][r] = ess\n",
    "    MFDB['logestimate'][r] = log_transition_estimate\n",
    "\n",
    "    # independent Metropolis-Hastings\n",
    "    initial = diffusion.simulate_bridge_forwards(score_transition_net, score_marginal_net, X0, XT, epsilon, 1, modify = True)\n",
    "    current_trajectory = initial['trajectories']\n",
    "    current_log_proposal = initial['logdensity'] \n",
    "    current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "    current_log_weight = current_log_target - current_log_proposal\n",
    "    num_accept = 0\n",
    "    for n in range(N):\n",
    "        proposed_trajectory = trajectories[n, :, :]\n",
    "        proposed_log_weight = log_weights[n]\n",
    "        log_accept_prob = proposed_log_weight - current_log_weight\n",
    "\n",
    "        if (torch.log(torch.rand(1)) < log_accept_prob):\n",
    "            current_trajectory = proposed_trajectory.clone()\n",
    "            current_log_weight = proposed_log_weight.clone()  \n",
    "            num_accept += 1\n",
    "    accept_rate = num_accept / N\n",
    "    MFDB['acceptrate'][r] = accept_rate\n",
    "\n",
    "    # print\n",
    "    print('Repeat: ' + str(r) + \n",
    "          ' ESS%: ' + str(float(ess * 100 / N)) + \n",
    "          ' log-transition density: ' + str(float(log_transition_estimate)),\n",
    "          ' Accept rate: ' + str(float(accept_rate)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward diffusion (FD) method of Pedersen (1995)\n",
    "drift = f\n",
    "FD = {'ess' : torch.zeros(R), 'logestimate' : torch.zeros(R), 'acceptrate' : torch.zeros(R)}\n",
    "\n",
    "for r in range(R):\n",
    "    output = diffusion.simulate_proposal_bridge(drift, X0, XT, N)\n",
    "    trajectories = output['trajectories']\n",
    "    log_proposal = output['logdensity']\n",
    "    log_target = diffusion.law_bridge(trajectories) \n",
    "    log_weights = log_target - log_proposal\n",
    "\n",
    "    # importance sampling\n",
    "    max_log_weights = torch.max(log_weights)\n",
    "    weights = torch.exp(log_weights - max_log_weights)\n",
    "    norm_weights = weights / torch.sum(weights)\n",
    "    ess = 1.0 / torch.sum(norm_weights**2)    \n",
    "    log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "    FD['ess'][r] = ess\n",
    "    FD['logestimate'][r] = log_transition_estimate\n",
    "\n",
    "    # independent Metropolis-Hastings\n",
    "    initial = diffusion.simulate_proposal_bridge(drift, X0, XT, 1)\n",
    "    current_trajectory = initial['trajectories']\n",
    "    current_log_proposal = initial['logdensity'] \n",
    "    current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "    current_log_weight = current_log_target - current_log_proposal\n",
    "    num_accept = 0\n",
    "    for n in range(N):\n",
    "        proposed_trajectory = trajectories[n, :, :]\n",
    "        proposed_log_weight = log_weights[n]\n",
    "        log_accept_prob = proposed_log_weight - current_log_weight\n",
    "\n",
    "        if (torch.log(torch.rand(1)) < log_accept_prob):\n",
    "            current_trajectory = proposed_trajectory.clone()\n",
    "            current_log_weight = proposed_log_weight.clone()  \n",
    "            num_accept += 1\n",
    "    accept_rate = num_accept / N\n",
    "    FD['acceptrate'][r] = accept_rate\n",
    "    \n",
    "    # print\n",
    "    print('Repeat: ' + str(r) + \n",
    "          ' ESS%: ' + str(float(ess * 100 / N)) + \n",
    "          ' log-transition density: ' + str(float(log_transition_estimate)),\n",
    "          ' Accept rate: ' + str(float(accept_rate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified diffusion bridge (MDB) method of Durham and Gallant (2002)\n",
    "drift = lambda t,x: (XT - x) / (T - t)\n",
    "MDB = {'ess' : torch.zeros(R), 'logestimate' : torch.zeros(R), 'acceptrate' : torch.zeros(R)}\n",
    "\n",
    "for r in range(R):\n",
    "    output = diffusion.simulate_proposal_bridge(drift, X0, XT, N, modify = True)\n",
    "    trajectories = output['trajectories']\n",
    "    log_proposal = output['logdensity']\n",
    "    log_target = diffusion.law_bridge(trajectories) \n",
    "    log_weights = log_target - log_proposal\n",
    "    \n",
    "    # importance sampling\n",
    "    max_log_weights = torch.max(log_weights)\n",
    "    weights = torch.exp(log_weights - max_log_weights)\n",
    "    norm_weights = weights / torch.sum(weights)\n",
    "    ess = 1.0 / torch.sum(norm_weights**2)\n",
    "    log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "    MDB['ess'] = ess\n",
    "    MDB['logestimate'] = log_transition_estimate\n",
    "\n",
    "    # independent Metropolis-Hastings\n",
    "    initial = diffusion.simulate_proposal_bridge(drift, X0, XT, 1, modify = True)\n",
    "    current_trajectory = initial['trajectories']\n",
    "    current_log_proposal = initial['logdensity'] \n",
    "    current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "    current_log_weight = current_log_target - current_log_proposal\n",
    "    num_accept = 0\n",
    "    for n in range(N):\n",
    "        proposed_trajectory = trajectories[n, :, :]\n",
    "        proposed_log_weight = log_weights[n]\n",
    "        log_accept_prob = proposed_log_weight - current_log_weight\n",
    "\n",
    "        if (torch.log(torch.rand(1)) < log_accept_prob):\n",
    "            current_trajectory = proposed_trajectory.clone()\n",
    "            current_log_weight = proposed_log_weight.clone()  \n",
    "            num_accept += 1\n",
    "    accept_rate = num_accept / N\n",
    "    MDB['acceptrate'][r] = accept_rate\n",
    "\n",
    "    # print\n",
    "    print('Repeat: ' + str(r) + \n",
    "          ' ESS%: ' + str(float(ess * 100 / N)) + \n",
    "          ' log-transition density: ' + str(float(log_transition_estimate)),\n",
    "          ' Accept rate: ' + str(float(accept_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion bridge proposal of Clark (1990) and Delyon and Hu (2006) (CDH)\n",
    "drift = lambda t,x: f(t,x) + (XT - x) / (T - t)\n",
    "CDH = {'ess' : torch.zeros(R), 'logestimate' : torch.zeros(R), 'acceptrate' : torch.zeros(R)}\n",
    "\n",
    "for r in range(R):\n",
    "    output = diffusion.simulate_proposal_bridge(drift, X0, XT, N, modify = False)\n",
    "    trajectories = output['trajectories']\n",
    "    log_proposal = output['logdensity']\n",
    "    log_target = diffusion.law_bridge(trajectories) \n",
    "    log_weights = log_target - log_proposal\n",
    "\n",
    "    # importance sampling\n",
    "    max_log_weights = torch.max(log_weights)\n",
    "    weights = torch.exp(log_weights - max_log_weights)\n",
    "    norm_weights = weights / torch.sum(weights)\n",
    "    ess = 1.0 / torch.sum(norm_weights**2)\n",
    "    log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "    CDH['ess'] = ess\n",
    "    CDH['logestimate'] = log_transition_estimate\n",
    "\n",
    "    # independent Metropolis-Hastings\n",
    "    initial = diffusion.simulate_proposal_bridge(drift, X0, XT, 1, modify = False)\n",
    "    current_trajectory = initial['trajectories']\n",
    "    current_log_proposal = initial['logdensity'] \n",
    "    current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "    current_log_weight = current_log_target - current_log_proposal\n",
    "    num_accept = 0\n",
    "    for n in range(N):\n",
    "        proposed_trajectory = trajectories[n, :, :]\n",
    "        proposed_log_weight = log_weights[n]\n",
    "        log_accept_prob = proposed_log_weight - current_log_weight\n",
    "\n",
    "        if (torch.log(torch.rand(1)) < log_accept_prob):\n",
    "            current_trajectory = proposed_trajectory.clone()\n",
    "            current_log_weight = proposed_log_weight.clone()  \n",
    "            num_accept += 1\n",
    "    accept_rate = num_accept / N\n",
    "    CDH['acceptrate'][r] = accept_rate\n",
    "\n",
    "    # print\n",
    "    print('Repeat: ' + str(r) + \n",
    "          ' ESS%: ' + str(float(ess * 100 / N)) + \n",
    "          ' log-transition density: ' + str(float(log_transition_estimate)),\n",
    "          ' Accept rate: ' + str(float(accept_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare ESS\n",
    "print('FD ESS%: ' + str(float(torch.mean(FD['ess']) * 100 / N)))\n",
    "print('MDB ESS%: ' + str(float(torch.mean(MDB['ess']) * 100 / N)))\n",
    "print('CDH ESS%: ' + str(float(torch.mean(CDH['ess']) * 100 / N)))\n",
    "print('BDB ESS%: ' + str(float(torch.mean(BDB['ess']) * 100 / N)))\n",
    "print('FDB ESS%: ' + str(float(torch.mean(FDB['ess']) * 100 / N)))\n",
    "print('MBDB ESS%: ' + str(float(torch.mean(MBDB['ess']) * 100 / N)))\n",
    "print('MFDB ESS%: ' + str(float(torch.mean(MFDB['ess']) * 100 / N)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare RMSE of log-transition density \n",
    "print('FD RMSE: ' + str(float(torch.sqrt(torch.mean((FD['logestimate'] - log_transition_density)**2)))))\n",
    "print('MDB RMSE: ' + str(float(torch.sqrt(torch.mean((MDB['logestimate'] - log_transition_density)**2)))))\n",
    "print('CDH RMSE: ' + str(float(torch.sqrt(torch.mean((CDH['logestimate'] - log_transition_density)**2)))))\n",
    "print('BDB RMSE: ' + str(float(torch.sqrt(torch.mean((BDB['logestimate'] - log_transition_density)**2)))))\n",
    "print('FDB RMSE: ' + str(float(torch.sqrt(torch.mean((FDB['logestimate'] - log_transition_density)**2)))))\n",
    "print('MBDB RMSE: ' + str(float(torch.sqrt(torch.mean((MBDB['logestimate'] - log_transition_density)**2)))))\n",
    "print('MFDB RMSE: ' + str(float(torch.sqrt(torch.mean((MFDB['logestimate'] - log_transition_density)**2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare indepedent Meteropolis-Hastings acceptance rate\n",
    "print('FD acceptance%: ' + str(float(torch.mean(FD['acceptrate'] * 100))))\n",
    "print('MDB acceptance%: ' + str(float(torch.mean(MDB['acceptrate'] * 100))))\n",
    "print('CDH acceptance%: ' + str(float(torch.mean(CDH['acceptrate'] * 100))))\n",
    "print('BDB acceptance%: ' + str(float(torch.mean(BDB['acceptrate'] * 100))))\n",
    "print('FDB acceptance%: ' + str(float(torch.mean(FDB['acceptrate'] * 100))))\n",
    "print('MBDB acceptance%: ' + str(float(torch.mean(MBDB['acceptrate'] * 100))))\n",
    "print('MFDB acceptance%: ' + str(float(torch.mean(MFDB['acceptrate'] * 100))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92682f8464e9044ba142483ddeefd87e1deb5806fbb1da5a3f470e5bd39935be"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
