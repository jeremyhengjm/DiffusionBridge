{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing methods to simulate cell differentiation and development model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DiffusionBridge as db\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from DiffusionBridge.auxiliary import AuxiliaryDiffusion\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify problem settings\n",
    "interval = 2\n",
    "sigma_level = \"smaller\"\n",
    "M = 100\n",
    "num_iterations = 1000\n",
    "path_dir = \".\"\n",
    "folder = \"results_cell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension\n",
    "d = 2\n",
    "\n",
    "# time interval\n",
    "T = torch.tensor(float(interval))\n",
    "\n",
    "# parameters\n",
    "alpha = torch.tensor(1.0)\n",
    "beta = torch.tensor(1.0)\n",
    "kappa = torch.tensor(1.0)\n",
    "p = torch.tensor(4.0)\n",
    "xi = torch.tensor(0.5)\n",
    "\n",
    "# drift\n",
    "def model_drift(x):\n",
    "    out = torch.zeros(x.shape)    \n",
    "    out[:,0] = alpha * x[:,0]**p / (xi**p + x[:,0]**p) + beta * xi**p / (xi**p + x[:,1]**p) - kappa * x[:,0]\n",
    "    out[:,1] = alpha * x[:,1]**p / (xi**p + x[:,1]**p) + beta * xi**p / (xi**p + x[:,0]**p) - kappa * x[:,1]\n",
    "    return out\n",
    "f = lambda t, x: model_drift(x)\n",
    "\n",
    "# diffusion coefficient\n",
    "if sigma_level == \"smaller\":\n",
    "    sigma = torch.sqrt(torch.tensor(1 * 1e-1))\n",
    "if sigma_level == \"larger\":\n",
    "    sigma = torch.tensor(1.0)\n",
    "\n",
    "# initialize diffusion model\n",
    "diffusion = db.diffusion.model(f, sigma, d, T, M)\n",
    "\n",
    "# sample size\n",
    "N = 2**10\n",
    "\n",
    "# repetitions\n",
    "R = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drift to find fixed points\n",
    "def drift_(x):\n",
    "    out = torch.zeros(d)    \n",
    "    out[0] = alpha * x[0]**p / (xi**p + x[0]**p) + beta * xi**p / (xi**p + x[1]**p) - kappa * x[0]\n",
    "    out[1] = alpha * x[1]**p / (xi**p + x[1]**p) + beta * xi**p / (xi**p + x[0]**p) - kappa * x[1]\n",
    "    return out\n",
    "\n",
    "# undifferentiated cell state\n",
    "X0 = torch.ones(d)\n",
    "print(f\"Undifferentiated cell state {X0} has drift {drift_(X0)}\")\n",
    "\n",
    "# differentiate cell state\n",
    "XT = torch.tensor(fsolve(func = drift_, x0 = torch.tensor([0.0, 2.0])), dtype = torch.float32)\n",
    "print(f\"Differentiated cell state {XT} has drift {drift_(XT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn backward diffusion bridge process with score matching\n",
    "epsilon = 1.0\n",
    "minibatch = 100\n",
    "learning_rate = 0.01\n",
    "ema_momentum = 0.99\n",
    "output = diffusion.learn_score_transition(\n",
    "    X0, XT, epsilon, minibatch, num_iterations, learning_rate, ema_momentum\n",
    ")\n",
    "score_transition_net = output['net']\n",
    "\n",
    "# simulate backward diffusion bridge (BDB) process with approximate score\n",
    "BDB = {\n",
    "    measure: torch.zeros(R) for measure in [\"ess\", \"logestimate\", \"acceptrate\"]\n",
    "}\n",
    "for r in range(R):\n",
    "    with torch.no_grad():\n",
    "        output = diffusion.simulate_bridge_backwards(\n",
    "            score_transition_net, X0, XT, epsilon, N\n",
    "        )\n",
    "        trajectories = output[\"trajectories\"]\n",
    "        log_proposal = output[\"logdensity\"]\n",
    "    log_target = diffusion.law_bridge(trajectories)\n",
    "    log_weights = log_target - log_proposal\n",
    "\n",
    "    # importance sampling\n",
    "    max_log_weights = torch.max(log_weights)\n",
    "    weights = torch.exp(log_weights - max_log_weights)\n",
    "    norm_weights = weights / torch.sum(weights)\n",
    "    ess = 1.0 / torch.sum(norm_weights**2)\n",
    "    log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "    BDB[\"ess\"][r] = ess\n",
    "    BDB[\"logestimate\"][r] = log_transition_estimate\n",
    "\n",
    "    # independent Metropolis-Hastings\n",
    "    initial = diffusion.simulate_bridge_backwards(\n",
    "        score_transition_net, X0, XT, epsilon, 1\n",
    "    )\n",
    "    current_trajectory = initial[\"trajectories\"]\n",
    "    current_log_proposal = initial[\"logdensity\"]\n",
    "    current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "    current_log_weight = current_log_target - current_log_proposal\n",
    "    num_accept = 0\n",
    "    for n in range(N):\n",
    "        proposed_trajectory = trajectories[n, :, :]\n",
    "        proposed_log_weight = log_weights[n]\n",
    "        log_accept_prob = proposed_log_weight - current_log_weight\n",
    "\n",
    "        if torch.log(torch.rand(1)) < log_accept_prob:\n",
    "            current_trajectory = proposed_trajectory.clone()\n",
    "            current_log_weight = proposed_log_weight.clone()\n",
    "            num_accept += 1\n",
    "    accept_rate = num_accept / N\n",
    "    BDB[\"acceptrate\"][r] = accept_rate\n",
    "\n",
    "    # print\n",
    "    print(\n",
    "        f\"BDB repetition: {r}\",\n",
    "        f\"ESS%: {float(ess * 100 / N):.2f}\",\n",
    "        f\"log-transition: {float(log_transition_estimate):.2f}\",\n",
    "        f\"Accept rate: {float(accept_rate):.4f}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drift functions of existing methods\n",
    "drifts = {}\n",
    "modify = {}\n",
    "\n",
    "# forward diffusion method of Pedersen (1995)\n",
    "drifts[\"FD\"] = f\n",
    "\n",
    "# modified diffusion bridge (MDB) method of Durham and Gallant (2002)\n",
    "drifts[\"MDB\"] = lambda t, x: (XT - x) / (T - t)\n",
    "modify[\"MDB\"] = \"variance\"\n",
    "\n",
    "# diffusion bridge proposal of Clark (1990) and Delyon and Hu (2006)\n",
    "auxiliary_type = \"bm\"\n",
    "initial_params = {\"alpha\": torch.zeros(d)}\n",
    "bm_auxiliary = AuxiliaryDiffusion(\n",
    "    diffusion, auxiliary_type, initial_params, requires_grad=False\n",
    ")\n",
    "drifts[\"CDH\"] = lambda t, x: f(t, x) + diffusion.Sigma * bm_auxiliary.grad_logh(\n",
    "    XT, t, x\n",
    ")\n",
    "modify[\"CDH\"] = \"time\"\n",
    "\n",
    "# learn guided proposal of Schauer, Van Der Meulen and Van Zanten\n",
    "auxiliary_type = \"ou-full\"\n",
    "initial_params = {\n",
    "    \"theta\": XT,\n",
    "    \"eigvals\": torch.ones(d),\n",
    "    \"eigvecs\": torch.eye(d),\n",
    "}\n",
    "ou_auxiliary = AuxiliaryDiffusion(diffusion, auxiliary_type, initial_params)\n",
    "\n",
    "minibatch = 100\n",
    "learning_rate = 0.01\n",
    "guided = diffusion.learn_guided_proposal(\n",
    "    ou_auxiliary, X0, XT, minibatch, num_iterations, learning_rate\n",
    ")\n",
    "drifts[\"GDB\"] = lambda t, x: f(t, x) + diffusion.Sigma * ou_auxiliary.grad_logh(\n",
    "    XT, t, x\n",
    ")\n",
    "modify[\"GDB\"] = \"time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate existing methods\n",
    "results = {\"BDB\": BDB}\n",
    "\n",
    "for method, drift in drifts.items():\n",
    "    # measures to store\n",
    "    result = {\n",
    "        measure: torch.zeros(R) for measure in [\"ess\", \"logestimate\", \"acceptrate\"]\n",
    "    }\n",
    "\n",
    "    # repetition\n",
    "    for r in range(R):\n",
    "        with torch.no_grad():\n",
    "            output = diffusion.simulate_proposal_bridge(\n",
    "                drift, X0, XT, N, modify.get(method)\n",
    "            )\n",
    "        trajectories = output[\"trajectories\"]\n",
    "        if method == \"CDH\":\n",
    "            log_weights = bm_auxiliary.log_radon_nikodym(trajectories)\n",
    "        elif method == \"GDB\":\n",
    "            log_weights = ou_auxiliary.log_radon_nikodym(trajectories)\n",
    "        else:\n",
    "            log_proposal = output[\"logdensity\"]\n",
    "            log_target = diffusion.law_bridge(trajectories)\n",
    "            log_weights = log_target - log_proposal\n",
    "\n",
    "        # importance sampling\n",
    "        max_log_weights = torch.max(log_weights)\n",
    "        weights = torch.exp(log_weights - max_log_weights)\n",
    "        norm_weights = weights / torch.sum(weights)\n",
    "        ess = 1.0 / torch.sum(norm_weights**2)\n",
    "        log_transition_estimate = torch.log(torch.mean(weights)) + max_log_weights\n",
    "        result[\"ess\"][r] = ess\n",
    "        result[\"logestimate\"][r] = log_transition_estimate\n",
    "\n",
    "        # independent Metropolis-Hastings\n",
    "        initial = diffusion.simulate_proposal_bridge(\n",
    "            drift, X0, XT, 1, modify.get(method)\n",
    "        )\n",
    "        current_trajectory = initial[\"trajectories\"]\n",
    "        if method == \"CDH\":\n",
    "            current_log_weight = bm_auxiliary.log_radon_nikodym(current_trajectory)\n",
    "        elif method == \"GDB\":\n",
    "            current_log_weight = ou_auxiliary.log_radon_nikodym(current_trajectory)\n",
    "        else:\n",
    "            current_log_proposal = initial[\"logdensity\"]\n",
    "            current_log_target = diffusion.law_bridge(current_trajectory)\n",
    "            current_log_weight = current_log_target - current_log_proposal\n",
    "        num_accept = 0\n",
    "        for n in range(N):\n",
    "            proposed_trajectory = trajectories[n, :, :]\n",
    "            proposed_log_weight = log_weights[n]\n",
    "            log_accept_prob = proposed_log_weight - current_log_weight\n",
    "            if torch.log(torch.rand(1)) < log_accept_prob:\n",
    "                current_trajectory = proposed_trajectory.clone()\n",
    "                current_log_weight = proposed_log_weight.clone()\n",
    "                num_accept += 1\n",
    "        accept_rate = num_accept / N\n",
    "        result[\"acceptrate\"][r] = accept_rate\n",
    "\n",
    "        # print\n",
    "        print(\n",
    "            f\"{method} repetition: {r}\",\n",
    "            f\"ESS%: {float(ess * 100 / N):.2f}\",\n",
    "            f\"log-transition: {float(log_transition_estimate):.2f}\",\n",
    "            f\"Accept rate: {float(accept_rate):.4f}\",\n",
    "        )\n",
    "\n",
    "    # store result\n",
    "    results[method] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare ESS\n",
    "for method, result in results.items():\n",
    "    print(\n",
    "        f\"{method}\",\n",
    "        f\"ESS%: {float(torch.mean(result['ess']) * 100 / N):.2f}\",\n",
    "    )\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# compare RMSE of log-transition density\n",
    "for method, result in results.items():\n",
    "    print(\n",
    "        f\"{method}\",\n",
    "        f\"ELBO: {torch.mean(result['logestimate']):.3f}\",\n",
    "    )\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# compare independent Meteropolis-Hastings acceptance rate\n",
    "for method, result in results.items():\n",
    "    print(\n",
    "        f\"{method}\",\n",
    "        f\"Accept rate%: {float(torch.mean(result['acceptrate']) * 100):.2f}\",\n",
    "    )\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "file_name = f\"{path_dir}/{folder}/cell_sigma_{sigma_level}_T{interval}\"\n",
    "torch.save(results, file_name + \".pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
